{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ac8cb6",
   "metadata": {},
   "source": [
    "# Setting up and training simple convolutional networks with tensorflow and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf29f6",
   "metadata": {},
   "source": [
    "In this tutorial, we will learn how to set up simple 3D convolutional network with tensorflow and keras.\n",
    "As an example, we will set up a network that takes a batch of 3D tensors with 2 channels (e.g. PET and MR) as input and outputs a batch of 3D tensors with 1 channel (denoised and deblurred PET image).\n",
    "Moreover, we will see how to train a model and how to monitor training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464949a5",
   "metadata": {},
   "source": [
    "The model that we will setup in this tutorial will look like the figure below, except that we won't split and\n",
    "concatenate the features in the first layer.\n",
    "\n",
    "![foo bar](https://raw.githubusercontent.com/gschramm/pyapetnet/master/figures/fig_1_apetnet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python modules used in this tutorial\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as mpimg\n",
    "from tempfile import NamedTemporaryFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1894e63",
   "metadata": {},
   "source": [
    "## Setting up a simple network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd51065a",
   "metadata": {},
   "source": [
    "Before setting up our first model, we define a short helper function that allows us to visualize models in a matplotlib figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712ae664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model(model):\n",
    "  \"\"\" function that saves structure of a model into png and shows it with matplotlib\n",
    "  \"\"\"\n",
    "  tmp_file = NamedTemporaryFile(prefix = 'model', suffix = '.png')\n",
    "  tf.keras.utils.plot_model(model, to_file= tmp_file.name, show_shapes = True, dpi = 192)\n",
    "  img = mpimg.imread(tmp_file)\n",
    "  fig, ax = plt.subplots(figsize = (12,12))\n",
    "  img = plt.imshow(img)\n",
    "  ax.set_axis_off()\n",
    "\n",
    "  return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2fa63f",
   "metadata": {},
   "source": [
    "Let's setup the network described above. We can setup the whole network with layers that are predefined in keras which makes life easy. Since our desired output (denoised and beblurred PET image) is \"close\" to first input channel (the noisy and blurry PET image), we add the first input channel to the output. The batch and spatial dimensions of all layers are \"None\", since all layers preserve those dimensions. This in turn means the model an be applied to all batch sizes and spatial dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d4ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "nfeat          = 20      # number of featuers for Conv3D layers\n",
    "kernel_shape   = (3,3,3) # kernel shapes for Conv3D layers\n",
    "nhidden_layers = 2       # number of hiddenlayers \n",
    "batch_norm     = True    # use batch normalization between Conv3D and activation\n",
    "add_final_relu = True    # add a final ReLU activation at the end to clip negative values\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# setup the input layer for batches of 3D tensors with two channels\n",
    "inp = tf.keras.layers.Input(shape = (None, None, None, 2), name = 'input_layer')\n",
    "\n",
    "# add a split layer such that we can add the first channel (PET) to the output\n",
    "split = tf.keras.layers.Lambda( lambda x: tf.split(x, num_or_size_splits = 2, axis = -1), name = 'split')(inp)\n",
    "\n",
    "# add all \"hidden\" layers\n",
    "x   = inp\n",
    "for i in range(nhidden_layers):\n",
    "  x = tf.keras.layers.Conv3D(nfeat, kernel_shape, padding = 'same',\n",
    "                             kernel_initializer = 'glorot_uniform', name = f'conv3d_{i+1}')(x)\n",
    "  if batch_norm:\n",
    "    x = tf.keras.layers.BatchNormalization(name = f'batchnorm_{i+1}')(x)\n",
    "  x = tf.keras.layers.PReLU(shared_axes=[1,2,3], name = f'prelu_{i+1}')(x)\n",
    "\n",
    "\n",
    "# add a (1,1,1) Conv layers with 1 feature to reduce along the feature dimension\n",
    "x = tf.keras.layers.Conv3D(1, (1,1,1), padding='same', name = 'conv_final',\n",
    "                           kernel_initializer = 'glorot_uniform')(x)\n",
    "\n",
    "# add first input channel\n",
    "x = tf.keras.layers.Add(name = 'add')([x] + [split[0]])\n",
    "\n",
    "# add a final ReLU to clip negative values\n",
    "if add_final_relu:\n",
    "  x = tf.keras.layers.ReLU(name = 'final_relu')(x)\n",
    "\n",
    "model  = tf.keras.Model(inputs = inp, outputs = x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b67c4",
   "metadata": {},
   "source": [
    "Let's print a summary of all layers, connections and the number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afbf99c",
   "metadata": {},
   "source": [
    "Let's visualize the model using the helper function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = show_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
