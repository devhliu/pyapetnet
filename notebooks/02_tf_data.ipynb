{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac31f2df",
   "metadata": {},
   "source": [
    "# Data processing and sampling with tensorflow data input pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6912b17",
   "metadata": {},
   "source": [
    "The aim of this tutorial is to learn how to:\n",
    "- read 3D images in nifiti format for training a neural network\n",
    "- use tensorflow Dataset for efficient sampling of mini batches and on the fly data augmentation\n",
    "\n",
    "This tutorial uses simulated PET/MR data and a network that has two input channels and one output channel. However, the basic concept of using a tensor data input pipeline generalizes easily to other examples using different data, different dimensions, or a different number of channels.\n",
    "\n",
    "This tutorial is inspired by  this keras tutorial https://keras.io/examples/vision/3D_image_classification/ on 3D CT image classifiction, which is also highly recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a173be0",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Efficient data sampling and data augmentation are crucial when training convolutional neural networks (CNN) - especially when using 3D images. Tensorflow offers tf.data.Dataset class which allows to do that in very elegant and efficient way. In the following we will read a few simulated PET and MR data sets that can be used to train a CNN for structure guided denoising and deconvolution of PET images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cce76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the modules that we need for this tutorial\n",
    "\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda01c8a",
   "metadata": {},
   "source": [
    "Make sure that the simulated brainweb PET/MR data sets were downloaded and that the main data path in the cell below is correct. Let's first find all data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2567bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory containing the simulated brain web data sets\n",
    "data_dir = pathlib.Path('../data/training_data/brainweb/export')\n",
    "batch_size = 10\n",
    "\n",
    "# get all the subjects paths\n",
    "subject_paths = list(data_dir.glob('subject??'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cd4a11",
   "metadata": {},
   "source": [
    "Each simulated data set contains a low resolution and noisy standard OSEM PET reconstruction, a high resolution and low noist T1 MR, and a high resolution and low noise target reconstruction. All images volumes are saved in nifti format. Let's define a first helper function that uses nibabel to load a 3D nifti volume in defined orientation (LPS). The standard orientation of nifti is RAW which is why we have to flip the 0 and 1 axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7cc4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nii_in_lps(fname):\n",
    "  \"\"\" function that loads nifti file and returns the volume and affine in \n",
    "      LPS orientation\n",
    "  \"\"\"\n",
    "  nii = nib.load(fname)\n",
    "  nii = nib.as_closest_canonical(nii)\n",
    "  vol = np.flip(nii.get_fdata(), (0,1))\n",
    "\n",
    "  return vol, nii.affine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a91e8a",
   "metadata": {},
   "source": [
    "When training neural networks, it is important to normalize the intensity of the input data. In the tutorial, we use a robust maximum which is the maximum of a heavily smoothed version of the input volume. The smoothing is important when working with noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f407e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_max(volume, n = 7):\n",
    "    \"\"\" function that return the max of a heavily smoothed version of the input volume\n",
    "        \n",
    "        for the smoothing we use tensorflows strided average pooling (which is fast) \n",
    "    \"\"\"\n",
    "    # to use tf's average pooling we first have to convert the numpy array to a tf tensor\n",
    "    # for the pooling layers, the shape of the input need to be [1,n0,n1,n2,1]\n",
    "    t = tf.convert_to_tensor(np.expand_dims(np.expand_dims(volume,0),-1).astype(np.float32))\n",
    "    \n",
    "    return tf.nn.avg_pool(t,2*n + 1,n,'SAME').numpy().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d32157e",
   "metadata": {},
   "source": [
    "Let's define another helper function that loads all 3 nifiti volumes of a data set and that also already performs an intensity normalization. For the latter, we divide both PET images by the 99.99 percentile of the OSEM volume, and the T1 MR by its 99.99 percentile. We could also divide by the maximum value, but the 99.99 percentile is more robust when working with noisy images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810933b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_set(subject_path, sim = 0, counts = 1e7):\n",
    "\n",
    "  # get the subject number from the path\n",
    "  data_id = int(subject_path.parts[-1][-2:])\n",
    "\n",
    "  # setup the file names\n",
    "  mr_file   = pathlib.Path(subject_path) / 't1.nii.gz'\n",
    "  osem_file = pathlib.Path(subject_path) / f'sim_{sim}' / f'osem_psf_counts_{counts:0.1E}.nii.gz'\n",
    "  target_file = pathlib.Path(subject_path) / f'sim_{sim}' / 'true_pet.nii.gz'\n",
    "\n",
    "  # load nifti files in RAS orientation\n",
    "  mr, mr_aff = load_nii_in_lps(mr_file)\n",
    "  osem, osem_aff = load_nii_in_lps(osem_file)\n",
    "  target, target_aff = load_nii_in_lps(target_file)\n",
    "\n",
    "  # normalize the intensities of the MR and PET volumes\n",
    "  mr_scale   = robust_max(mr)\n",
    "  osem_scale = robust_max(osem)\n",
    "\n",
    "  mr     /= mr_scale\n",
    "  osem   /= osem_scale\n",
    "  target /= osem_scale\n",
    "\n",
    "  return osem, mr, target, osem_scale, mr_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ac682",
   "metadata": {},
   "source": [
    "Now let's loop over all data directories and let's store all images in 2 big numpy arrays. The first array ```x_train``` should contain the input and the second array ```y_train``` the target for our CNN during training. When working with 3D volumes, the shape of the input and output to the CNN has to be ```(nbatch,n0,n1,n2,nchannels)``` where ```nbatch``` is the mini batch length, ```n0,n1,n2``` are the spatial dimentions, and ```nchannels``` are the number of input channels. In this example, we have two input channels (OSEM PET and T1 MR) and one output channel (target PET image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7da3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "osem_vols   = []\n",
    "t1_vols     = []\n",
    "target_vols = []\n",
    "\n",
    "# load all the data sets\n",
    "for subject_path in subject_paths:\n",
    "  print(f'loading {subject_path}')\n",
    "\n",
    "  data = load_data_set(subject_path, sim = 0, counts = 1e7)\n",
    "\n",
    "  osem_vols.append(data[0])\n",
    "  t1_vols.append(data[1])\n",
    "  target_vols.append(data[2])\n",
    "\n",
    "osem_vols   = np.array(osem_vols)\n",
    "t1_vols     = np.array(t1_vols)\n",
    "target_vols = np.array(target_vols)\n",
    "\n",
    "x_train = np.stack((osem_vols,t1_vols), axis = -1)\n",
    "y_train = np.expand_dims(target_vols, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426826be",
   "metadata": {},
   "source": [
    "In many CNN training scenarios, on-the-fly data augmentation (e.g. cropping, rotating, change of contrast) is very useful. Moreover, when working with 3D data sets, networks are often trained on smaller patches due to memory limitations on the available GPUs. \n",
    "Here, we define a function that samples a random 3D patch from the entire input and target data sets. The function uses 3 random numbers to determine the center of a smaller path with size ```(s0,s1,s2)```. Moreover, we define margins along all directions ```m0,m1,m2``` to avoid sampling of small empty patches (patches that only consist of background). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4056a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_augmentation(x, y, s0 = 64, s1 = 64, s2 = 64, m0 = (40,40), m1 = (40,40), m2 = (40,40)):\n",
    "  \"\"\"data augmentation function for training \"\"\"\n",
    "\n",
    "  # extract a random sub volume\n",
    "  sh0 = tf.cast(tf.math.ceil(s0/2), tf.int32)\n",
    "  sh1 = tf.cast(tf.math.ceil(s1/2), tf.int32)\n",
    "  sh2 = tf.cast(tf.math.ceil(s2/2), tf.int32)\n",
    "\n",
    "  lm0 = tf.math.maximum(sh0, m0[0])\n",
    "  rm0 = tf.math.maximum(sh0, m0[1])\n",
    "\n",
    "  lm1 = tf.math.maximum(sh1, m1[0])\n",
    "  rm1 = tf.math.maximum(sh1, m1[1])\n",
    "\n",
    "  lm2 = tf.math.maximum(sh2, m2[0])\n",
    "  rm2 = tf.math.maximum(sh2, m2[1])\n",
    "\n",
    "  i0 = tf.random.uniform((), minval=lm0, maxval=x.shape[0]-rm0, dtype=tf.dtypes.int32) - sh0\n",
    "  i1 = tf.random.uniform((), minval=lm1, maxval=x.shape[1]-rm1, dtype=tf.dtypes.int32) - sh1\n",
    "  i2 = tf.random.uniform((), minval=lm2, maxval=x.shape[2]-rm2, dtype=tf.dtypes.int32) - sh2\n",
    "\n",
    "  x_crop = tf.slice(x, begin = [i0,i1,i2,0], size = [s0,s1,s2,2])\n",
    "  y_crop = tf.slice(y, begin = [i0,i1,i2,0], size = [s0,s1,s2,1])\n",
    "\n",
    "  return x_crop, y_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab1f2b2",
   "metadata": {},
   "source": [
    "Let's create a tensorflow data set from our numpy arrays stored in the host memory ```x_train, y_train```. Moreover, we use the ```shuffle``` and ```map``` methods to shuffle the data and to apply our defined data augmentation function on the fly. More information on the tensorflow dataset class can be found here: https://www.tensorflow.org/api_docs/python/tf/data/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49350c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "\n",
    "train_dataset = train_loader.shuffle(len(x_train)).map(lambda x,y: train_augmentation(x,y, s0 = 179, s1 = 179, s2 = 179)).batch(batch_size).prefetch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ebf1b",
   "metadata": {},
   "source": [
    "Finally, let's draw a mini-batch and let's visualize the first 4 3D data sets in the mini batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = list(train_dataset.take(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymirc.viewer as pv\n",
    "for i in range(4):\n",
    "  vi = pv.ThreeAxisViewer([x_batch[i,...,0].numpy().squeeze(), x_batch[i,...,1].numpy().squeeze(), \n",
    "                           y_batch[i,...,0].numpy().squeeze()],\n",
    "                           imshow_kwargs = {'vmin':0,'vmax':1.4}, rowlabels = [f'd{i} input 0', f'd{i} input 1', f'd{i} target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf68b07",
   "metadata": {},
   "source": [
    "## Now it's your turn - recommended exercises\n",
    "Now it is your turn, to familiarize yourself with the tensorflow dataset input pipeline:\n",
    "1. Modify ```train_data``` to get different spatial dimensions (e.g. 65,65,65)\n",
    "2. Write your own on-the-fly data augmentation function that: \n",
    "   - randomly inverts the contrast of the input MR image\n",
    "   - randomly rotates the input and target images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e2cde",
   "metadata": {},
   "source": [
    "## What's next\n",
    "In the following notebooks we will learn:\n",
    "- how to setup a simple convolutional neural network (CNN) in tensorflow\n",
    "- how to train a CNN with our data input pipeline\n",
    "- how to monitor training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
